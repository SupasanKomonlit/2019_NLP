{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn_crfsuite import CRF\n",
    "# ref for first module https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_line( directory , file ):\n",
    "    file = open( directory + \"/\" + file , \"r\" , encoding=\"utf-8\" )\n",
    "    contents = file.read()\n",
    "    file.close()\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    dict_type = sent[i][2]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'dictionary' : dict_type\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        dict_type1 = sent[i-1][2]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:dictionay' : dict_type1\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        dict_type1 = sent[i+1][2]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '-1:dictionay' : dict_type1\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label, dict_type in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label, dict_type in sent]\n",
    "\n",
    "def sent2dict_type( sent ):\n",
    "    return [dict_type for token, label, dict_type in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 0\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, t, d) for w, t, d in zip( s[\"Word\"].values.tolist(),\n",
    "                                                            s[\"Tag\"].values.tolist(),\n",
    "                                                            s[\"Dictionary\"].values.tolist() \n",
    "                                                          )]\n",
    "        self.grouped = self.grouped_sentence()\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def grouped_sentence( self ):\n",
    "        save_sentence = 0\n",
    "        major_index = 0\n",
    "        temp_grouped = []\n",
    "        for run in range( 0 , self.data.shape[0] ):\n",
    "            temp_sentence = num_of_sentence( self.data[\"Sentence #\"][ run ] )\n",
    "            if save_sentence != temp_sentence :\n",
    "                major_index = temp_sentence - 1\n",
    "                save_sentence = temp_sentence\n",
    "                temp_grouped.append( [] )\n",
    "            temp_grouped[ major_index ].append( (self.data[\"Word\"][run], \n",
    "                                                 self.data[\"Tag\"][run],\n",
    "                                                 self.data[\"Dictionary\"][run] ) )\n",
    "        return temp_grouped\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[ self.n_sent ]\n",
    "            self.n_sent += 1\n",
    "            return s  \n",
    "        except:\n",
    "            self.empty = True\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_group_sentence( data ):\n",
    "    old_tag = []\n",
    "    save_sentence = \"\"\n",
    "    run_old = -1\n",
    "    for run in range(  0 , data.shape[0] ):\n",
    "        if( save_sentence != data[\"Sentence #\"][ run ] ):\n",
    "            old_tag.append( [] )\n",
    "            run_old += 1\n",
    "        else:\n",
    "            None\n",
    "        if data.Tag[run] in ( '' ):\n",
    "            old_tag[ run_old ].append( 'O' )\n",
    "        else:\n",
    "            old_tag[ run_old ].append( data.Tag[ run ] )\n",
    "    return old_tag\n",
    "\n",
    "def merge_all_tag( data ):\n",
    "    old_tag = []\n",
    "    save_sentence = \"\"\n",
    "    run_old = -1\n",
    "    for run in range(  0 , data.shape[0] ):\n",
    "        if( save_sentence != data[\"Sentence #\"][ run ] ):\n",
    "            old_tag.append( [] )\n",
    "            run_old += 1\n",
    "        else:\n",
    "            None\n",
    "        if data.Tag[run] in ( '' ):\n",
    "            old_tag[ run_old ].append( 'O' )\n",
    "            data.Tag[run] = 'O'\n",
    "        elif data.Tag[run] in ('loc_cont','loc_end','loc_start'):\n",
    "            old_tag[ run_old ].append( data.Tag[ run ] )\n",
    "            data.Tag[run] = 'loc'\n",
    "        elif data.Tag[run] in ('org_cont','org_end','org_start'):\n",
    "            old_tag[ run_old ].append( data.Tag[ run ] )\n",
    "            data.Tag[run] = 'org'\n",
    "        elif data.Tag[run] in ('per_cont','per_end','per_start'):\n",
    "            old_tag[ run_old ].append( data.Tag[ run ] )\n",
    "            data.Tag[run] = 'per'\n",
    "        else:\n",
    "            old_tag[ run_old ].append( data.Tag[ run ] )\n",
    "            None\n",
    "    return old_tag\n",
    "\n",
    "# number is current index\n",
    "# target is -1 -2 +1 +2 what do you want to file\n",
    "def helper_get_tag( data , number , target , limit ):\n",
    "    if( number + target == limit ):\n",
    "        return 'O'\n",
    "    elif( data[\"Sentence #\"][ number+target ] != data[\"Sentence #\"][ number ] ):\n",
    "        return 'O'\n",
    "    else:\n",
    "        return data.Tag[number + target ]\n",
    "            \n",
    "def split_all_tag( data ):\n",
    "    limit_run = data.shape[0]\n",
    "    for run in range( 0 , limit_run ):\n",
    "        if data.Tag[ run ] == \"loc\" :\n",
    "            if( helper_get_tag( data , run , -1, limit_run  ) in ( \"loc_start\" , \"loc_cont\" ) ):\n",
    "                if( helper_get_tag( data , run , +1 , limit_run ) == \"loc\" ):\n",
    "                    data.Tag[ run ] = \"loc_cont\"\n",
    "                else:\n",
    "                    data.Tag[ run ] = \"loc_end\"\n",
    "            elif( helper_get_tag( data , run , +1 , limit_run ) == \"loc\" ):\n",
    "                data.Tag[ run ] = \"loc_start\"\n",
    "        elif data.Tag[ run ] == \"org\" :\n",
    "            if( helper_get_tag( data , run , -1 , limit_run ) in ( \"org_start\" , \"org_cont\" ) ):\n",
    "                if( helper_get_tag( data , run , +1 , limit_run ) == \"org\" ):\n",
    "                    data.Tag[ run ] = \"org_cont\"\n",
    "                else:\n",
    "                    data.Tag[ run ] = \"org_end\"\n",
    "            elif( helper_get_tag( data , run , +1 , limit_run ) == \"org\" ):\n",
    "                data.Tag[ run ] = \"org_start\"\n",
    "        elif data.Tag[ run ] == \"per\" :\n",
    "            if( helper_get_tag( data , run , -1 , limit_run ) in ( \"per_start\" , \"per_cont\" ) ):\n",
    "                if( helper_get_tag( data , run , +1, limit_run ) == \"per\" ):\n",
    "                    data.Tag[ run ] = \"per_cont\"\n",
    "                else:\n",
    "                    data.Tag[ run ] = \"per_end\"\n",
    "            elif( helper_get_tag( data , run , +1 , limit_run ) == \"per\" ):\n",
    "                data.Tag[ run ] = \"per_start\"\n",
    "            else:\n",
    "                None\n",
    "        else:\n",
    "            None\n",
    "\n",
    "def convert_list_to_data_frame( data_frame , data_list ):\n",
    "    save_sentence = 0\n",
    "    major_index_list = 0\n",
    "    minor_index_list = 0\n",
    "    for run in range( 0 , data_frame.shape[0] ):\n",
    "        temp_sentence = num_of_sentence( data_frame[\"Sentence #\"][ run ] )\n",
    "        if save_sentence != temp_sentence :\n",
    "            major_index_list = temp_sentence - 1\n",
    "            save_sentence = temp_sentence\n",
    "            minor_index_list = 0\n",
    "        data_frame[\"Tag\"][run] = data_list[ major_index_list][ minor_index_list ]\n",
    "        minor_index_list += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dictionary( directory , file_dict ):\n",
    "    dictionary = {}\n",
    "    for key in file_dict.keys():\n",
    "        dictionary[ key ] = []\n",
    "        list_file = file_dict[ key ]\n",
    "        if type( list_file ) == type( \"test_string\" ):\n",
    "            dictionary[ key ] = read_all_line( directory , list_file ).split('\\n')\n",
    "        else:\n",
    "            for file in list_file:\n",
    "                dictionary[ key ] += read_all_line( directory , file ).split('\\n')\n",
    "    return dictionary\n",
    "\n",
    "# If found in dict will return key other return NO\n",
    "def search_in_dictionary( word , dictionary ):\n",
    "    answer = \"NO\"\n",
    "    for key in dictionary.keys():\n",
    "        if word in dictionary[key]:\n",
    "            answer = key\n",
    "            break\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_directory = \"dictionary_directory\"\n",
    "dictionary_files = {\n",
    "    \"front_person\" : (\"clue front.txt\" , \"clue word person.txt\" , \"clue_royal.txt\")\n",
    "    ,\"front_country\" : (\"คำนำหน้าชื่อประเทศ.txt\")\n",
    "    ,\"front_org\" : (\"คำนำหน้าองค์กรจาก dict.txt\")\n",
    "    ,\"location_name\" : (\"ชื่อกิ่งอำเภอ.txt\" , \"ชื่อคลอง.txt\" , \"ชื่อจังหวัด.txt\" , \"ชื่อตำบล.txt\" , \"ชื่อมลรัฐ.txt\" , \"ชื่อสถานที่.txt\")\n",
    "}\n",
    "dictionary = prepare_dictionary( dictionary_directory , dictionary_files )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idividual_read_file( raw_data , split_sentence , count ,remove = [] ):\n",
    "    pre_data_frame = { \"Sentence #\" : [] , \"Word\" : [] , \"Tag\" : [] , \"Dictionary\" : [] }\n",
    "    for word in raw_data:\n",
    "        if word in remove :\n",
    "            None\n",
    "        elif word in split_sentence :\n",
    "            count += 1\n",
    "        else: \n",
    "            check = word.find('(')\n",
    "            if check > 0:\n",
    "                temp_word = word[ 0 : word.find('(')]\n",
    "                pre_data_frame[\"Sentence #\"].append( \"Sentence: \" + str(count) )\n",
    "                pre_data_frame[\"Word\"].append( temp_word )\n",
    "                pre_data_frame[\"Tag\"].append( word[ word.find('(') + 1 : word.find(')')] )\n",
    "                pre_data_frame[\"Dictionary\"].append( search_in_dictionary( temp_word , dictionary ) )\n",
    "            else:\n",
    "                pre_data_frame[\"Sentence #\"].append( \"Sentence: \" + str(count) )\n",
    "                pre_data_frame[\"Word\"].append( word )\n",
    "                pre_data_frame[\"Tag\"].append( \"O\" )\n",
    "                pre_data_frame[\"Dictionary\"].append( search_in_dictionary( word , dictionary ) )\n",
    "    return pre_data_frame , count\n",
    "\n",
    "def read_file( directory , list_file , count = 1 , individual = False ):\n",
    "    data_frame = pd.DataFrame( { \"Sentence #\" : [] , \"Word\" : [] , \"Tag\" : [] , \"Dictionary\" : []} )\n",
    "    if( individual ):\n",
    "        word = read_all_line( directory , list_file ).split('|')\n",
    "        pre_data_frame , count = idividual_read_file( word , # raw_data\n",
    "                                              [\"\\n\"] , # word show split sentence\n",
    "                                              count , # order of sentence\n",
    "                                              [ \" \" , '' , '\\0'] ) # word to delete or prevent\n",
    "        data_frame  = data_frame.append( pd.DataFrame( pre_data_frame ), ignore_index=True )\n",
    "    else:\n",
    "        for file in list_file :\n",
    "            word = read_all_line( directory , file ).split('|')\n",
    "            pre_data_frame , count = idividual_read_file( word ,\n",
    "                                              [\"\\n\"] ,\n",
    "                                              count ,\n",
    "                                              [ \" \" , '' , '\\0'] )\n",
    "            data_frame  = data_frame.append( pd.DataFrame( pre_data_frame ), ignore_index=True )\n",
    "    return data_frame\n",
    "def num_of_sentence( sentence ):\n",
    "    words = sentence.split( \" \")\n",
    "    return int( words[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable for collect name file and access file\n",
    "train_directory = \"corpus_directory\"\n",
    "train_files = (\"Politic9.txt\" , \"Allcolumn.txt\" , \"98JUL5_1.txt\" ,\n",
    "                \"98JUL5_2.txt\" , \"bkknews1.txt\" , \"Result1.txt\" ,\n",
    "                \"Result2(corpus-1).txt\" , \"Result3(corpus-2).txt\" )\n",
    "test_directory = \"corpus_directory\"\n",
    "test_files = (\"result4.txt\" , \"Result_c_2_1.txt\", \"Result_c_2_2.txt\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Dictionary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>\"</td>\n",
       "      <td>O</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>พลอากาศเอก</td>\n",
       "      <td>O</td>\n",
       "      <td>front_person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>ทักษิณ</td>\n",
       "      <td>per</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>\"</td>\n",
       "      <td>O</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>ขอ</td>\n",
       "      <td>O</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52217</td>\n",
       "      <td>Sentence: 3762</td>\n",
       "      <td>ประกาศ</td>\n",
       "      <td>O</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52218</td>\n",
       "      <td>Sentence: 3762</td>\n",
       "      <td>หลักเกณฑ์</td>\n",
       "      <td>O</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52219</td>\n",
       "      <td>Sentence: 3762</td>\n",
       "      <td>และ</td>\n",
       "      <td>O</td>\n",
       "      <td>location_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52220</td>\n",
       "      <td>Sentence: 3762</td>\n",
       "      <td>จำนวน</td>\n",
       "      <td>O</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52221</td>\n",
       "      <td>Sentence: 3762</td>\n",
       "      <td>ทรัพย์สิน</td>\n",
       "      <td>O</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52222 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sentence #        Word  Tag     Dictionary\n",
       "0         Sentence: 1           \"    O             NO\n",
       "1         Sentence: 1  พลอากาศเอก    O   front_person\n",
       "2         Sentence: 1      ทักษิณ  per             NO\n",
       "3         Sentence: 1           \"    O             NO\n",
       "4         Sentence: 1          ขอ    O             NO\n",
       "...               ...         ...  ...            ...\n",
       "52217  Sentence: 3762      ประกาศ    O             NO\n",
       "52218  Sentence: 3762   หลักเกณฑ์    O             NO\n",
       "52219  Sentence: 3762         และ    O  location_name\n",
       "52220  Sentence: 3762       จำนวน    O             NO\n",
       "52221  Sentence: 3762   ทรัพย์สิน    O             NO\n",
       "\n",
       "[52222 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_file( train_directory , train_files , 1 )\n",
    "data.fillna( method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tag_data = merge_all_tag( data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter( data )\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=False,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = CRF(algorithm='lbfgs',\n",
    "          c1=0.1,\n",
    "          c2=0.1,\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=False)\n",
    "crf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = \"model_directory\"\n",
    "model_name = \"CRF_dictionary.sav\"\n",
    "model_file = model_directory + \"/\" + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump( crf , open( model_file , 'wb') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = read_file( test_directory , test_files , 1 )\n",
    "data_test.fillna( method=\"ffill\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_data_tag_test = merge_all_tag( data_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter_test = SentenceGetter( data_test )\n",
    "sentences_test = getter_test.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = [sent2features(s) for s in sentences_test]\n",
    "test_predict = crf.predict( test_set )\n",
    "convert_list_to_data_frame( data_test , test_predict )\n",
    "split_all_tag( data_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Dictionary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>มา</td>\n",
       "      <td>O</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>พูด</td>\n",
       "      <td>O</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>คุย</td>\n",
       "      <td>O</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>กัน</td>\n",
       "      <td>O</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>ถึง</td>\n",
       "      <td>O</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36377</td>\n",
       "      <td>Sentence: 2064</td>\n",
       "      <td>และ</td>\n",
       "      <td>org_cont</td>\n",
       "      <td>location_name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36378</td>\n",
       "      <td>Sentence: 2064</td>\n",
       "      <td>ประมง</td>\n",
       "      <td>org_cont</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36379</td>\n",
       "      <td>Sentence: 2064</td>\n",
       "      <td>ทะเล</td>\n",
       "      <td>org_end</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36380</td>\n",
       "      <td>Sentence: 2064</td>\n",
       "      <td>จังหวัด</td>\n",
       "      <td>O</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36381</td>\n",
       "      <td>Sentence: 2064</td>\n",
       "      <td>ภูเก็ต</td>\n",
       "      <td>loc</td>\n",
       "      <td>location_name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36382 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Sentence #     Word       Tag     Dictionary\n",
       "0         Sentence: 1       มา         O             NO\n",
       "1         Sentence: 1      พูด         O             NO\n",
       "2         Sentence: 1      คุย         O             NO\n",
       "3         Sentence: 1      กัน         O             NO\n",
       "4         Sentence: 1      ถึง         O             NO\n",
       "...               ...      ...       ...            ...\n",
       "36377  Sentence: 2064      และ  org_cont  location_name\n",
       "36378  Sentence: 2064    ประมง  org_cont             NO\n",
       "36379  Sentence: 2064     ทะเล   org_end             NO\n",
       "36380  Sentence: 2064  จังหวัด         O             NO\n",
       "36381  Sentence: 2064   ภูเก็ต       loc  location_name\n",
       "\n",
       "[36382 rows x 4 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = get_tag_group_sentence( data_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['org'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['org'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['org'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['org'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['org'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org'],\n",
       " ['O'],\n",
       " ['per'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['O'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['per_start'],\n",
       " ['per_cont'],\n",
       " ['per_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['org_start'],\n",
       " ['org_cont'],\n",
       " ['org_end'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['loc'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ['O'],\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O       0.96      0.99      0.97     29673\n",
      "         loc       0.90      0.58      0.71      1127\n",
      "    loc_cont       0.11      0.19      0.14        54\n",
      "     loc_end       0.35      0.46      0.40        74\n",
      "   loc_start       0.39      0.51      0.44        74\n",
      "         org       0.84      0.61      0.71      1176\n",
      "    org_cont       0.79      0.71      0.75      1027\n",
      "     org_end       0.71      0.65      0.68       656\n",
      "   org_start       0.73      0.66      0.69       671\n",
      "         per       0.88      0.41      0.56       331\n",
      "    per_cont       0.83      0.89      0.86       541\n",
      "     per_end       0.91      0.85      0.88       489\n",
      "   per_start       0.91      0.85      0.88       489\n",
      "\n",
      "    accuracy                           0.93     36382\n",
      "   macro avg       0.72      0.64      0.67     36382\n",
      "weighted avg       0.93      0.93      0.93     36382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = flat_classification_report(y_pred=test_predict, y_true=old_data_tag_test)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
